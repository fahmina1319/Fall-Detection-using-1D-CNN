#improt libraries 

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix


# Load the datasets
train_df = pd.read_csv('SmartFall_Training.csv')
test_df = pd.read_csv('SmartFall_Testing.csv')


#Sliding Window Aprroach

def sliding_window_df(data, size, stride):
    segments = []
    labels = []
    for start in range(0, len(data) - size, stride):
        end = start + size
        segment = data[start:end, :-1]
        label_data = data[start:end, -1].astype(int)
        label = np.bincount(label_data).argmax()
        segments.append(segment)
        labels.append(label)
    return np.array(segments), np.array(labels)


window_size = 35
stride = 15

X_train, y_train = sliding_window_df(train_df.values, window_size, stride)
X_test, y_test = sliding_window_df(test_df.values, window_size, stride)


# Converting to PyTorch tensors

X_train_tensor = torch.tensor(X_train).float()
y_train_tensor = torch.tensor(y_train).long()
X_test_tensor = torch.tensor(X_test).float()
y_test_tensor = torch.tensor(y_test).long()

!pip install torchmetrics

# Create DataLoader
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

class CNN1D(nn.Module):
    def __init__(self):
        super(CNN1D, self).__init__()
        self.conv1 = nn.Conv1d(3, 64, kernel_size=3)
        self.relu = nn.ReLU()
        self.conv2 = nn.Conv1d(64, 128, kernel_size=3)
        self.fc1 = nn.Linear(128 * 31, 128)
        self.fc2 = nn.Linear(128, 2)

    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = x.view(x.size(0), -1)  # Flatten
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Initialize the model, loss function, and optimizer
model = CNN1D()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Training loop
num_epochs = 10
for epoch in range(num_epochs):
    for i, (inputs, labels) in enumerate(train_loader):
        optimizer.zero_grad()
        outputs = model(inputs.permute(0, 2, 1))
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')

# Predict on test set
model.eval()
with torch.no_grad():
    logits = model(X_test_tensor.permute(0, 2, 1))
    probabilities = torch.softmax(logits, dim=1)
    y_pred = probabilities.max(1)[1]
    fall_probabilities = probabilities[:, 1]
    average_fall_probability = fall_probabilities.mean().item()

# Print the average fall probability
print(f"Average Probability of Fall in the Test Set: {average_fall_probability * 100:.2f}%")

# Calculate accuracy, confusion matrix, and classification report
accuracy = (y_pred == y_test_tensor).float().mean()
print(f'Accuracy: {accuracy.item() * 100:.2f}%')

conf_mat = confusion_matrix(y_test_tensor, y_pred)
print('Confusion Matrix:\n', conf_mat)

class_report = classification_report(y_test_tensor, y_pred)
print('Classification Report:\n', class_report)
